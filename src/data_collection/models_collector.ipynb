{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nikita/anaconda3/envs/rag_env/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from typing import Literal, Optional\n",
    "from urllib.parse import parse_qs, urlparse\n",
    "from huggingface_hub.utils import get_session, hf_raise_for_status\n",
    "from tqdm import tqdm\n",
    "from dotenv import load_dotenv\n",
    "import aiohttp\n",
    "import asyncio\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(\".env\")\n",
    "HF_TOKEN = os.getenv(\"HF_TOKEN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_TOTAL_MODELS = 20000\n",
    "BATCH_SIZE_LIST_MODELS = 100\n",
    "BATCH_SIZE_FETCH_MODEL_INFO = 50\n",
    "TIME_OUT = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelIterator:\n",
    "    def __init__(self, items: list[dict], next_cursor: Optional[str] = None):\n",
    "        self.items = items\n",
    "        self.next_cursor = next_cursor\n",
    "\n",
    "    def __iter__(self):\n",
    "        yield from self.items\n",
    "\n",
    "\n",
    "def list_models_with_cursor(\n",
    "    *,\n",
    "    limit: int = 100,\n",
    "    direction: Optional[Literal[-1]] = None,\n",
    "    cursor: Optional[str] = None,\n",
    ") -> ModelIterator:\n",
    "    \"\"\"\n",
    "    List models with cursor-based pagination.\n",
    "    \"\"\"\n",
    "    url = \"https://huggingface.co/api/models\"\n",
    "    params = {\n",
    "        \"limit\": limit,\n",
    "        \"direction\": direction,\n",
    "        \"cursor\": cursor,\n",
    "        \"full\": False,\n",
    "        \"cardData\": False,\n",
    "        \"fetch_config\": False,\n",
    "    }\n",
    "\n",
    "    headers = {\"Authorization\": f\"Bearer {HF_TOKEN}\"}\n",
    "\n",
    "    response = get_session().get(url, params=params, headers=headers)\n",
    "\n",
    "    # Add timeout if status code is 429 (Too Many Requests)\n",
    "    if response.status_code == 429:\n",
    "        retry_after = int(response.headers.get(\"Retry-After\", TIME_OUT))\n",
    "        print(f\"Rate limit exceeded. Waiting for {retry_after} seconds...\")\n",
    "        import time\n",
    "\n",
    "        time.sleep(retry_after)\n",
    "        # Retry the request after waiting\n",
    "        response = get_session().get(url, params=params, headers=headers)\n",
    "\n",
    "    hf_raise_for_status(response)\n",
    "    next_url = response.links.get(\"next\", {}).get(\"url\")\n",
    "    next_cursor = None\n",
    "    if next_url:\n",
    "        next_cursor = parse_qs(urlparse(next_url).query)[\"cursor\"][0]\n",
    "\n",
    "    return ModelIterator(response.json(), next_cursor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def fetch_model_info(session, model_name: str) -> dict:\n",
    "    url = f\"https://huggingface.co/api/models/{model_name}\"\n",
    "    headers = {\"Authorization\": f\"Bearer {HF_TOKEN}\"}\n",
    "    async with session.get(url, headers=headers) as response:\n",
    "        # Add timeout if status code is 429 (Too Many Requests)\n",
    "        if response.status == 429:\n",
    "            retry_after = int(response.headers.get(\"Retry-After\", TIME_OUT))\n",
    "            await asyncio.sleep(retry_after)\n",
    "            # Retry the request after waiting\n",
    "            async with session.get(url, headers=headers) as retry_response:\n",
    "                return await retry_response.json()\n",
    "        return await response.json()\n",
    "\n",
    "\n",
    "async def fetch_model_info_batch_async(model_names: list[str]) -> list[dict]:\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        tasks = [fetch_model_info(session, model_name) for model_name in model_names]\n",
    "        return await asyncio.gather(*tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_to_model_type = {\n",
    "    \"audio-text-to-text\": \"Multimodal\",\n",
    "    \"image-text-to-text\": \"Multimodal\",\n",
    "    \"visual-question-answering\": \"Multimodal\",\n",
    "    \"document-question-answering\": \"Multimodal\",\n",
    "    \"video-text-to-text\": \"Multimodal\",\n",
    "    \"visual-document-retrieval\": \"Multimodal\",\n",
    "    \"any-to-any\": \"Multimodal\",\n",
    "    \"depth-estimation\": \"Computer Vision\",\n",
    "    \"image-classification\": \"Computer Vision\",\n",
    "    \"object-detection\": \"Computer Vision\",\n",
    "    \"image-segmentation\": \"Computer Vision\",\n",
    "    \"text-to-image\": \"Computer Vision\",\n",
    "    \"image-to-text\": \"Computer Vision\",\n",
    "    \"image-to-image\": \"Computer Vision\",\n",
    "    \"image-to-video\": \"Computer Vision\",\n",
    "    \"unconditional-image-generation\": \"Computer Vision\",\n",
    "    \"video-classification\": \"Computer Vision\",\n",
    "    \"text-to-video\": \"Computer Vision\",\n",
    "    \"zero-shot-image-classification\": \"Computer Vision\",\n",
    "    \"mask-generation\": \"Computer Vision\",\n",
    "    \"zero-shot-object-detection\": \"Computer Vision\",\n",
    "    \"text-to-3d\": \"Computer Vision\",\n",
    "    \"image-to-3d\": \"Computer Vision\",\n",
    "    \"image-feature-extraction\": \"Computer Vision\",\n",
    "    \"keypoint-detection\": \"Computer Vision\",\n",
    "    \"text-classification\": \"Natural Language Processing\",\n",
    "    \"token-classification\": \"Natural Language Processing\",\n",
    "    \"table-question-answering\": \"Natural Language Processing\",\n",
    "    \"question-answering\": \"Natural Language Processing\",\n",
    "    \"zero-shot-classification\": \"Natural Language Processing\",\n",
    "    \"translation\": \"Natural Language Processing\",\n",
    "    \"summarization\": \"Natural Language Processing\",\n",
    "    \"feature-extraction\": \"Natural Language Processing\",\n",
    "    \"text-generation\": \"Natural Language Processing\",\n",
    "    \"text2text-generation\": \"Natural Language Processing\",\n",
    "    \"fill-mask\": \"Natural Language Processing\",\n",
    "    \"sentence-similarity\": \"Natural Language Processing\",\n",
    "    \"text-to-speech\": \"Audio\",\n",
    "    \"text-to-audio\": \"Audio\",\n",
    "    \"automatic-speech-recognition\": \"Audio\",\n",
    "    \"audio-to-audio\": \"Audio\",\n",
    "    \"audio-classification\": \"Audio\",\n",
    "    \"voice-activity-detection\": \"Audio\",\n",
    "    \"tabular-classification\": \"Tabular\",\n",
    "    \"tabular-regression\": \"Tabular\",\n",
    "    \"time-series-forecasting\": \"Tabular\",\n",
    "    \"reinforcement-learning\": \"Reinforcement Learning\",\n",
    "    \"robotics\": \"Reinforcement Learning\",\n",
    "    \"graph-machine-learning\": \"Other\",\n",
    "}\n",
    "\n",
    "\n",
    "def extract_model_features(model_name: str, model_info: dict) -> dict:\n",
    "    \"\"\"\n",
    "    Extract key features from a model's information dictionary.\n",
    "\n",
    "    Args:\n",
    "        model_info (dict): Dictionary containing model information\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionary with extracted features\n",
    "    \"\"\"\n",
    "    features = {\n",
    "        \"model_name\": model_name,\n",
    "    }\n",
    "\n",
    "    # Model size (in billions of parameters)\n",
    "    if \"safetensors\" in model_info and \"total\" in model_info[\"safetensors\"]:\n",
    "        # Convert from bytes to billions\n",
    "        features[\"model_size\"] = model_info[\"safetensors\"][\"total\"]\n",
    "    else:\n",
    "        features[\"model_size\"] = None\n",
    "\n",
    "    # Number of downloads\n",
    "    features[\"downloads\"] = model_info.get(\"downloads\", 0)\n",
    "\n",
    "    # Number of likes\n",
    "    features[\"likes\"] = model_info.get(\"likes\", 0)\n",
    "\n",
    "    # Task category (pipeline_tag)\n",
    "    features[\"task_category\"] = model_info.get(\"pipeline_tag\", None)\n",
    "\n",
    "    # Model category (from tags or library_name)\n",
    "    features[\"model_category\"] = pipeline_to_model_type.get(\n",
    "        features[\"task_category\"], None\n",
    "    )\n",
    "\n",
    "    # Model creators (author)\n",
    "    features[\"creators\"] = model_info.get(\"author\", None)\n",
    "\n",
    "    # Date of publishing (createdAt)\n",
    "    features[\"publishing_date\"] = model_info.get(\"createdAt\", None)\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [01:24<00:00,  2.37it/s]\n"
     ]
    }
   ],
   "source": [
    "prev_cursor = None\n",
    "model_names = []\n",
    "for i in tqdm(range(N_TOTAL_MODELS // BATCH_SIZE_LIST_MODELS)):\n",
    "    response = list_models_with_cursor(limit=BATCH_SIZE_LIST_MODELS, cursor=prev_cursor)\n",
    "    prev_cursor = response.next_cursor\n",
    "    model_names.extend([model[\"modelId\"] for model in response.items])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [09:49<00:00,  1.47s/it]\n"
     ]
    }
   ],
   "source": [
    "models_info = []\n",
    "\n",
    "for i in tqdm(range(N_TOTAL_MODELS // BATCH_SIZE_FETCH_MODEL_INFO)):\n",
    "    res = await fetch_model_info_batch_async(\n",
    "        model_names[\n",
    "            i * BATCH_SIZE_FETCH_MODEL_INFO : (i + 1) * BATCH_SIZE_FETCH_MODEL_INFO\n",
    "        ]\n",
    "    )\n",
    "    models_info.extend(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_features = [\n",
    "    extract_model_features(model_name, model_info)\n",
    "    for model_name, model_info in zip(model_names, models_info)\n",
    "]\n",
    "df = pd.DataFrame(model_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"./data/models_info.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
